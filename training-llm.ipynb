{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install unsloth because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [215 lines of output]\n",
      "      running bdist_wheel\n",
      "      C:\\Users\\gunes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\cpp_extension.py:495: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "        warnings.warn(msg.format('we could not find ninja.'))\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\attn_bias_utils.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\checkpoint.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\info.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\test.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\utils.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\_cpp_lib.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\_deprecation_warning.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      copying xformers\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_attn_decoding.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_core.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_indexing.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_mem_eff_attention.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_merge_attentions.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_multi_head_dispatch.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_nystrom_utils.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_revnet.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sddmm.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sequence_parallel_fused.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sp24.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_swiglu.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_tiled_matmul.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\utils.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\activations.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\input_projection.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\multi_head_dispatch.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\patch_embedding.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\residual.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\reversible.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\simplicial_embedding.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      copying xformers\\components\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\block_configs.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\block_factory.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\hydra_helper.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\model_factory.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\weight_init.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      copying xformers\\factory\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\factory\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\helpers\n",
      "      copying xformers\\helpers\\hierarchical_configs.py -> build\\lib.win-amd64-cpython-311\\xformers\\helpers\n",
      "      copying xformers\\helpers\\test_utils.py -> build\\lib.win-amd64-cpython-311\\xformers\\helpers\n",
      "      copying xformers\\helpers\\timm_sparse_attention.py -> build\\lib.win-amd64-cpython-311\\xformers\\helpers\n",
      "      copying xformers\\helpers\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\helpers\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\common.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\differentiable_collectives.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\indexing.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\ipc.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\modpar_layers.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\rmsnorm.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\rope_padded.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\seqpar.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\sequence_parallel_fused_ops.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\sp24.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\swiglu_op.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\tiled_matmul.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\unbind.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      copying xformers\\ops\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\api.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\device_limits.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\find_slowest.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler_dcgm.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler_dcgm_impl.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profile_analyzer.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      copying xformers\\profiler\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\profiler\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      copying xformers\\sparse\\blocksparse_tensor.py -> build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      copying xformers\\sparse\\csr_tensor.py -> build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      copying xformers\\sparse\\utils.py -> build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      copying xformers\\sparse\\_csr_ops.py -> build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      copying xformers\\sparse\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\sparse\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\triton\n",
      "      copying xformers\\triton\\vararg_kernel.py -> build\\lib.win-amd64-cpython-311\\xformers\\triton\n",
      "      copying xformers\\triton\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\triton\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\bert_padding.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_interface.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_triton.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_triton_og.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_blocksparse_attention.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_blocksparse_attn_interface.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\fused_softmax.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\batch_fetch_results.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\batch_submit.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_grid_search.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_tasks.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_with_submitit.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\dataset.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\model_wrapper.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\benchmarks\\LRA\\code\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\attention_mask.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\attention_patterns.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\base.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\compositional.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\core.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\favor.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\fourier_mix.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\global_tokens.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\lambda_layer.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\linformer.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\local.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\nystrom.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\ortho.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\pooling.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\random.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\scaled_dot_product.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\sparsity_config.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\utils.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\visual.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\_sputnik_sparse.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\base.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\conv_mlp.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\mixture_of_experts.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\mlp.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\feedforward\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\base.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\param.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\rotary.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\sine.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\vocab.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\positional_embedding\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\base.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\softmax.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\components\\attention\\feature_maps\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\attn_bias.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck_decoder.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck_splitk.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\common.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\cutlass.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\dispatch.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\flash.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\flash3.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\torch_attention_compat.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\triton_splitk.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\fmha\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\k_index_select_cat.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\k_scaled_index_add.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\rmsnorm_kernels.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\rope_padded_kernels.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\sequence_parallel_fused_kernels.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\tiled_matmul_kernels.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\ops\\_triton\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\patch_embed.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\rotary.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\layers\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\losses\n",
      "      copying xformers\\_flash_attn\\losses\\cross_entropy.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\losses\n",
      "      copying xformers\\_flash_attn\\losses\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\losses\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\baichuan.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\bert.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\bigcode.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\btlm.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\falcon.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gpt.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gptj.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gpt_neox.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\llama.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\opt.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\vit.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\models\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\block.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\embedding.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\mha.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\mlp.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\modules\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\activations.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\fused_dense.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\layer_norm.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\rms_norm.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\benchmark.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\distributed.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\generation.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\pretrained.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\utils\n",
      "      creating build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\cross_entropy.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\k_activations.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\layer_norm.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\linear.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\mlp.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\rotary.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\__init__.py -> build\\lib.win-amd64-cpython-311\\xformers\\_flash_attn\\ops\\triton\n",
      "      running build_ext\n",
      "      C:\\Users\\gunes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\cpp_extension.py:380: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "        warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "      building 'xformers._C' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for xformers\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\n",
      "ERROR: Could not find a version that satisfies the requirement triton (from versions: none)\n",
      "ERROR: No matching distribution found for triton\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes xformers datasets -q\n",
    "!pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch>=2.0.0 transformers>=4.30.0 peft>=0.3.0 datasets>=2.10.0 trl>=0.4.1 bitsandbytes>=0.39.0 accelerate>=0.20.0 scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: huggingface-hub\n",
      "Version: 0.25.2\n",
      "Summary: Client library to download and publish models, datasets and other repos on the huggingface.co hub\n",
      "Home-page: https://github.com/huggingface/huggingface_hub\n",
      "Author: Hugging Face, Inc.\n",
      "Author-email: julien@huggingface.co\n",
      "License: Apache\n",
      "Location: C:\\Users\\gunes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\n",
      "Requires: filelock, fsspec, packaging, pyyaml, requests, tqdm, typing-extensions\n",
      "Required-by: accelerate, datasets, peft, tokenizers, transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the notebook_login function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Login to Hugging Face\u001b[39;00m\n\u001b[0;32m      5\u001b[0m notebook_login()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "# Import the notebook_login function\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to Hugging Face\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel, unsloth_save_model\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "# notebook_login()\n",
    "\n",
    "# Check if dataset files exist\n",
    "train_file_path = \"train.jsonl\"\n",
    "valid_file_path = \"valid.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_file_path):\n",
    "    print(f\"File not found: {train_file_path}. Please ensure the file is in the correct directory.\")\n",
    "if not os.path.exists(valid_file_path):\n",
    "    print(f\"File not found: {valid_file_path}. Please ensure the file is in the correct directory.\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": train_file_path, \"validation\": valid_file_path})\n",
    "\n",
    "# Model setup\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")\n",
    "\n",
    "# PEFT setup\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    lora_alpha = 32,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 42,\n",
    "    max_seq_length = max_seq_length\n",
    ")\n",
    "\n",
    "# Training setup\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    max_steps=1000,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"gunzzz24/gemma-2b-4bit-resume\",  # Replace with your custom name\n",
    ")\n",
    "\n",
    "# Define a formatting function\n",
    "def formatting_func(example):\n",
    "    # The data is already formatted, so we just return it as is\n",
    "    return example['text']\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    max_seq_length=256,\n",
    "    formatting_func=formatting_func\n",
    ")\n",
    "\n",
    "# Train\"\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "unsloth_save_model(model, tokenizer, \"unsloth_fine_tuned_gemma_2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
